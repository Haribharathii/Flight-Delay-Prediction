{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Basics\n",
    "In this module, you'll be acquiring and handling datasets. You will be using the Cinema Data, Salary Data and Reviews Data for the tasks in this module. <br> <br>\n",
    "**Pipeline:**\n",
    "* Acquiring the data\n",
    "* Handling files and formats\n",
    "* Data Analysis\n",
    "* Prediction\n",
    "* Analysing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from os import listdir\n",
    "import csv\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [............................................................................] 849446 / 849446"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'CinemaData (4).json'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i='https://sf-mlbasics.firebaseio.com/CinemaData.json'\n",
    "wget.download(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [..................................................................................] 320 / 320"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4d13184683407dfb0b36c7130fce1567.txt'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f='https://gist.github.com/solarillionfoundation/4d13184683407dfb0b36c7130fce1567.txt'\n",
    "wget.download(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Data Acquisition\n",
    "* Retrieve the CinemaData dataset from Firebase, convert it to a CSV and save it in the 'Data' folder as 'CinemaData.csv'. You may use shell scripts, other packages and any other resources you require to do this. The database can be accessed with a HTTP request, ask a TA for the link. <br> \n",
    "* Using `wget`, download the 'SalaryData.txt' and save it in the 'Data' folder. Convert it to a CSV named 'SalaryData.csv' and save it in the same folder. It is avaliable at this link: <br>\n",
    "http://rebrand.ly/ml_salarydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('CinemaData.json') as json_file:\n",
    "    jsondata = json.load(json_file)\n",
    " \n",
    "data_file = open('CinemaData.json.csv', 'w', newline='')\n",
    "csv_writer = csv.writer(data_file)\n",
    " \n",
    "count = 0\n",
    "for data in jsondata:\n",
    "    if count == 0:\n",
    "        header = data.keys()\n",
    "       \n",
    "        csv_writer.writerow(header)\n",
    "        count += 1\n",
    "        \n",
    "    csv_writer.writerow(data.values())\n",
    "   \n",
    " \n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file=pd.read_csv('SalaryData.txt')\n",
    "csv_file=txt_file.to_csv('SalaryData.csv',index=None)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Dataset Handling\n",
    "* You can find the Reviews Data in a RAR file in the 'Data' directory. Extract this dataset and use it for this module.\n",
    "\n",
    "* The dataset contains positive and negative movie reviews. The files 'Positive_Reviews.txt' and 'Negative_Reviews.txt' contain names of files having positive and negative reviews respectively. Create two directories ‘pos’ and ‘neg’, and segregate the reviews accordingly into the two directories.\n",
    "\n",
    "* Load ‘cv000_29590.csv’ and report the number of words present in the first column.\n",
    "\n",
    "* Find the number of unique words in the first column. For this task, ignore punctuations, that is, punctuations are not considered as a word or a part of it.\n",
    "\n",
    "* Lookups: OS module, String functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial():\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    test=[]\n",
    "    source_path = \"C://Users/harib/Desktop/solarillion/ML-1/Reviews/\"\n",
    "    \n",
    "    file1 = open(\"Negative_Reviews.txt\",\"r+\") \n",
    "    file2 = open(\"Positive_Reviews.txt\",\"r+\") \n",
    "    \n",
    "    read1=file1.read()\n",
    "    read2=file2.read()\n",
    "    \n",
    "    x = read1.split(\",\")\n",
    "    x1 = read2.split(\",\")\n",
    "    \n",
    "    dir_list = os.listdir(source_path)\n",
    "    \n",
    "    for i in x:\n",
    "        temp=i.replace(\"'\",\"\")    \n",
    "\n",
    "        if \"[\" in i:\n",
    "            temp=i.replace(\"[\",\"\")\n",
    "            test.append(temp)\n",
    "        \n",
    "        if \"]\" in i:\n",
    "            temp=i.replace(\"]\",\"\")\n",
    "            test.append(temp)\n",
    "        \n",
    "        test.append(temp)\n",
    "    test=list(set(test))\n",
    "    #print(len(test))\n",
    "    \n",
    "    for space in test:\n",
    "        temp=space.replace(\" \",\"\")\n",
    "        str2.append(temp)\n",
    "    \n",
    "    #print(len(str2))\n",
    "    test.clear()\n",
    "    \n",
    "    for i in x1:\n",
    "        temp=i.replace(\"'\",\"\")    \n",
    "\n",
    "        if \"[\" in i:\n",
    "            temp=i.replace(\"[\",\"\")\n",
    "            test.append(temp)\n",
    "        \n",
    "        if \"]\" in i:\n",
    "            temp=i.replace(\"]\",\"\")\n",
    "            test.append(temp)\n",
    "        test.append(temp)\n",
    "    \n",
    "    test=list(set(test))\n",
    "    \n",
    "    for space in test:\n",
    "        temp=space.replace(\" \",\"\")\n",
    "        str3.append(temp)\n",
    "    \n",
    "    test.clear()\n",
    "    #print(len(str3))\n",
    "\n",
    "    for j in dir_list:\n",
    "         str1.append(str(j))\n",
    "    #print(len(str1))\n",
    "\n",
    "    return str1,str2,str3,source_path\n",
    "\n",
    "\n",
    "         \n",
    "           \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_review():\n",
    "    str1,str2,str3,source_path=initial()\n",
    "    pos_path= \"C://Users/harib/Desktop/solarillion/ML-1/pos/\"\n",
    "    neg_path=\"C://Users/harib/Desktop/solarillion/ML-1/neg/\"\n",
    "    \n",
    "    for i in str2:\n",
    "        if i in str1:\n",
    "            for f in dir_list:\n",
    "                try: \n",
    "                    os.rename(source_path  + i, neg_path + i)\n",
    "                except FileNotFoundError: \n",
    "                     pass \n",
    "\n",
    "    for i in str3:\n",
    "        if i in str1:\n",
    "            for f in dir_list:\n",
    "                try: \n",
    "                    os.rename(source_path  + i, pos_path + i)\n",
    "                except FileNotFoundError: \n",
    "                     pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in first column is 232\n",
      "Number of unique words is 171\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def remove(split2):\n",
    "    while '' in split2:\n",
    "        split2.remove('')\n",
    "    return split2  \n",
    "\n",
    "\n",
    "\n",
    "def word():\n",
    "    word_list=[]\n",
    "    temp=[]\n",
    "    split2=[]\n",
    "    unique=[]\n",
    "    punc = '''!()-[]{};:'\"\\ ,<>./?@#$%^&*_~'''\n",
    "    txt_file1=pd.read_csv(r\"C://Users/harib/Desktop/solarillion/ML-1/pos/cv000_29590.txt\")\n",
    "    headerl=[1,2,3,4,5,6]\n",
    "    csv_file1=txt_file1.to_csv(r\"C://Users/harib/Desktop/solarillion/ML-1/cv000_29590.csv\",index=None,header=headerl)\n",
    "    file1=open(\"cv000_29590.csv\",'r')\n",
    "    col_list = [\"1\", \"2\",\"3\",\"4\"]\n",
    "    df = pd.read_csv(\"cv000_29590.csv\", usecols=col_list)\n",
    "    df=df.rename(columns={'1':'l','2':'m','3':'n','4':'o'})\n",
    "\n",
    "    for i in range(len(df[\"l\"])):\n",
    "        word_list.append(df.l[i])\n",
    "\n",
    "\n",
    "    for j in word_list:\n",
    "        split=j.split(\" \")\n",
    "        if split not in split2:\n",
    "            split2=split+split2\n",
    "\n",
    "    remove(split2)\n",
    "\n",
    "    for l in split2:\n",
    "        for ele in l:\n",
    "            if ele in punc:\n",
    "                l= l.replace(ele, \"\")\n",
    "        temp.append(l)\n",
    "\n",
    "    remove(temp)\n",
    "\n",
    "    print(f'Number of words in first column is {len(temp)}')\n",
    "    for k in temp:\n",
    "        if k not in unique:\n",
    "            unique.append(k)\n",
    "    print(f'Number of unique words is {len(unique)}')\n",
    "\n",
    "    \n",
    "word()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
